---
title: "PSL (F20) Coding Assignment 2"
author: "Vijayakumar Sitha Mohan (VS24), Waitong Matthew Leung (wmleung2)"
date: '13-Sept-2020'
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
set.seed(8742)
```

## Introduction

Implement Lasso using the Coordinate Descent (CD) algorithm and apply our algorithm
on the Boston housing data. The goal is to check the accuracy of our implementation compare to the output of glmnet.The maximum difference between the two coefficient matrices should be less than 0.005.


## Data Preparation

Load required R packages and apply proper transformations on the Boston Housing Data.

```{r}

library(MASS)
library(glmnet)
myData = Boston
names(myData)[14] = "Y"
iLog = c(1, 3, 5, 6, 8, 9, 10, 14);
myData[, iLog] = log(myData[, iLog]);
myData[, 2] = myData[, 2] / 10;
myData[, 7] = myData[, 7]^2.5 / 10^4
myData[, 11] = exp(0.4 * myData[, 11]) / 1000;
myData[, 12] = myData[, 12] / 100;
myData[, 13] = sqrt(myData[, 13]);
X = as.matrix(myData[, -14])
y = myData$Y
lam.seq = c(0.30, 0.2, 0.1, 0.05, 0.02, 0.005)

```


## CD for Lasso

Implement the Coordinate Descent algorithm for Lasso in the function MyLasso here.

```{r}

# function to solve the Lasso estimate for Î²j given other coefficients fixed
one_var_lasso = function(r, x, lam) {
    xx = sum(x^2)
    xr = sum(r * x)
    b = (abs(xr) - lam/2)/xx
    b = sign(xr) * ifelse(b > 0, b, 0)
    return(b)
}


MyLasso = function(X, y, lam.seq, maxit = 50) {
    
    # X: n-by-p design matrix without the intercept 
    # y: n-by-1 response vector 
    # lam.seq: sequence of lambda values 
    # maxit: number of updates for each lambda 
    # Center/Scale X
    # Center y
  
    n = length(y)
    p = dim(X)[2]
    nlam = length(lam.seq)
  
    ##############################
    # YOUR CODE: 
    # Record the corresponding means and scales
    # For example, 
    # y.mean = mean(y)
    # yc = centered y
    # Xs = centered and scaled X
    
    y.mean = mean(y)
    yc = y - y.mean
    
    X.mean = apply(X, 2, mean)
    X.sd = sqrt(apply((X - rep(X.mean, rep.int(nrow(X), ncol(X))))^2, 2, mean))
    Xs = (X - rep(X.mean, rep.int(nrow(X), ncol(X)))) / rep(X.sd, rep.int(nrow(X), ncol(X)))
    
    ############################## 
    
    

    # Initilize coef vector b and residual vector r
    b = rep(0, p)
    r = yc
    B = matrix(nrow = nlam, ncol = p + 1)
    
    # Triple nested loop
    for (m in 1:nlam) {
        lam = 2 * n * lam.seq[m]
        for (step in 1:maxit) {
            for (j in 1:p) {
                r = r + (Xs[, j] * b[j])
                b[j] = one_var_lasso(r, Xs[, j], lam)
                r = r - Xs[, j] * b[j]
            }
        }
        B[m, ] = c(0, b)
    }
   
    ##############################
    # YOUR CODE:
    # Scale back the coefficients;
    # Update the intercepts stored in B[, 1]

    B[, 1] = y.mean - apply(B[,2:(p+1)] * rep(X.mean/X.sd, rep.int(nlam, p)), 1, sum)
    B[, 2:(p+1)] = B[, 2:(p+1)]/ rep(X.sd, rep.int(nlam, p))
    B
    ##############################
}

```



## Results : Check the Accuracy

```{r}

lam.seq = c(0.30 , 0.2 , 0.1 , 0.05 , 0.02 , 0.005)
lasso.fit = glmnet (X, y, alpha = 1, lambda = lam.seq)
coef ( lasso.fit )

myout = MyLasso(X, y, lam.seq , maxit = 50)
myout = t(myout)
rownames(myout) = c("Intercept", colnames(X))
myout
max(abs(coef(lasso.fit) - myout))

```



## Discussion


## Contribution

Vijayakumar Mohan contributes 

Matthew Leung contributes to