---
title: "PSL (F20) Coding Assignment 4"
author: "Vijayakumar Sitha Mohan (VS24), Waitong Matthew Leung (wmleung2)"
date: '3-Nov-2020'
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
set.seed(8742)
```

## Introduction

Implement the EM algorithm for a p-dimensional Gaussian mixture model with G components:

$\sum_{k=1}^{G} P_i * N(x; \mu_k, \Sigma)$

Store the estimated parameters as a list in R with three components

- prob: G-dimensional probability vector (p1,...,pG)

- mean: p-by-G matrix with the k-th column being $\mu_k$, the p-dimensional mean for the
k-th Gaussian component;

- Sigma: p-by-p covariance matrix $\Sigma$ shared by all G components.


## Prepare my function

We prepare a function to perform the E-step, a function to perform the M-step, and then iteratively call these two functions in myEM.


```{r}



Estep <- function(data, G, para){
  # Your Code
  # Return the n-by-G probability matrix
  
  # initialize pre_r = pi_k * N(x_i|mu_k, sigma) with n x G zeros
  pre_r = matrix(0, nrow(data), G)
  
  # loop through each data point i
  for (i in 1:nrow(data)){
    # loop through each class c
    for (c in 1:G){
      pre_r[i,c] = para$prob[c] * dmvnorm(data[i,], para$mean[,c], para$Sigma)
    }#c      
  }#i
  
  # calculate responsibility r
  r = matrix(0, nrow(data), G)
  r = pre_r/apply(pre_r, 1, sum)

  # return responsibility r
  r
  
}

Mstep <- function(data, G, para, post.prob){ 
  # Your Code
  # Return the updated parameters
  

  mySigma = matrix(0,G,G)
  # loop through all class
  for (c in 1:G){
    
    # calculate sigma, do this first before updating mean
    # subtract class mean from data and convert to matrix
    mydata = data.matrix(data - rep(para$mean[,c], rep.int(nrow(data),G)))
    
    mySigma = mySigma + 
      para$prob[c] * t(mydata) %*% mydata
    
    # update mean
    para$mean[,c] = apply(data * post.prob[,c], 2, sum)/ sum(post.prob[,c])
    
  } 
  
  # update Sigma
  para$Sigma = mySigma/nrow(data)
  
  para  
}

myEM <- function(data, itmax, G, para){
  # itmax: num of iterations
  # G:     num of components
  # para:  list of parameters (prob, mean, Sigma)
  for(t in 1:itmax){
    post.prob <- Estep(data, G, para)
    para <- Mstep(data, G, para, post.prob)
  }
  return(para)
}


```



## Test my function

Test my function with data faithful from mclust.


### Load data

```{r}

library(mclust)
dim(faithful)


```


```{r}
head(faithful)

```

```{r}
n <- nrow(faithful)

```


### Initialization

The mixture model in this assignment correponds to modelName = "EEE" in mclust. We initialize parameters by first randomly assigning the n samples into two groups and then running one iteration of the built-in M-step.

```{r}

set.seed(8742)
Z <- matrix(0, n, 2) 
Z[sample(1:n, 120), 1] <- 1 
Z[, 2] <- 1 - Z[, 1]
ini0 <- mstep(modelName="EEE", faithful , Z)$parameters

```

Here are the initial values we use for (prob, mean, Sigma).


```{r}

para0 <- list(prob = ini0$pro, 
              mean = ini0$mean, 
              Sigma = ini0$variance$Sigma)
para0

```



### Compare Results

Compare the estimated parameters returned by myEM and the ones returned by the EM algorithm in mclust after 10 iterations.

- Output from myEM


```{r}

myEM(data=faithful, itmax=10, G=2, para=para0)

```


- Output from mclust


```{r}

Rout <- em(modelName = "EEE", data = faithful,
           control = emControl(eps=0, tol=0, itmax = 10), 
           parameters = ini0)$parameters

list(Rout$pro, Rout$mean, Rout$variance$Sigma)

```



## Discussion



## Contribution

Vijayakumar Mohan contributes to verification of implementation and enhancement of visualization.

Matthew Leung contributes to implementation of LOO-CV/GCV and overall presentation of the report
