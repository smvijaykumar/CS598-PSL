---
title: "PSL (F20) Project 1"
author: "Vijayakumar Sitha Mohan (VS24), Waitong Matthew Leung (wmleung2)"
date: '13-Sept-2020'
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
set.seed(8742)

library(dplyr)
library(tidyr)
library(caret)
library(tidyr)
library(knitr)
library(randomForest)
library(xgboost)
library(glmnet)
library(e1071)
```

## Introduction


```{r}

hotEncoding = function(dataset) {
  dummies_model = dummyVars(Sale_Price ~ . -PID, data=dataset)
  dataset = predict(dummies_model, newdata = dataset)
  dataset = data.frame(dataset)
}

RMSE = function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

winsorize = function(data) {
  winsor.vars <- c( "Lot_Area", "Mas_Vnr_Area", "BsmtFin_SF_2", "Bsmt_Unf_SF", "Total_Bsmt_SF", "Second_Flr_SF", 'First_Flr_SF', "Gr_Liv_Area", "Garage_Area", "Wood_Deck_SF", "Open_Porch_SF", "Enclosed_Porch", "Three_season_porch", "Screen_Porch", "Misc_Val")
  
  quan.value <- 0.95
  for(var in winsor.vars){
      tmp <- data[, var]
      myquan <- quantile(tmp, probs = quan.value, na.rm = TRUE)
      tmp[tmp > myquan] <- myquan
      data[, var] <- tmp
  }
  data
}

removeVars = function(data) {

  remove.var <- c('Street', 'Utilities',  'Condition_2', 'Roof_Matl', 'Heating', 'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude','Latitude',"Lot_Frontage")
  data[,!names(data) %in% remove.var]
}

getSkewedVars = function(data) {
  skewedVars <- NA

  for(i in names(data)){
    if(is.numeric(data[,i])){
      if((i != "Sale_Price") & (i != "PID")){
        if(length(levels(as.factor(data[,i]))) > 10){
          # Enters this block if variable is non-categorical
          skewVal <- skewness(data[,i])
          print(paste(i, skewVal, sep = ": "))
          if(abs(skewVal) > 0.25){
            skewedVars <- c(skewedVars, i)
          }
        }
      }
    }
  }
  skewedVars[-1]
}

applyLogTransformation = function() {
  
log.train <- new.Train
log.test <- new.Test

for(i in skewedVars){
  if(0 %in% new.Train[, i]){
    log.train[,i] <- log(1+new.Train[,i])
    log.test[,i] <- log(1+new.Test[,i])
  }
  else{
    log.train[,i] <- log(new.Train[,i])
    log.test[,i] <- log(new.Test[,i])
  }
}

for(i in skewedVars){
  if(0 %in% new.Train[, i]){
    dummyVector <- ifelse(log.train[,i] > 0, 1, 0)
    log.train <- data.frame(log.train, factor(dummyVector))
    colnames(log.train)[ncol(log.train)] <- paste(i, "ZERO", sep="")

    dummyVector <- ifelse(log.test[,i] > 0, 1, 0)
    log.test <- data.frame(log.test, factor(dummyVector))
    colnames(log.test)[ncol(log.test)] <- paste(i, "ZERO", sep="")
  }
}

}
```

```{r}
data = read.csv("Ames_data.csv")
data = removeVars(data)
d <- preProcess(data, "medianImpute")
data = predict(d,data)
#data = winsorize(data)

skewed.vars = getSkewedVars(data)
data_encoded = hotEncoding(data)

for(i in skewed.vars){
  if(0 %in% data_encoded[, i]){
    data_encoded[,i] <- log(1+data_encoded[,i])
  }
  else{
    data_encoded[,i] <- log(data_encoded[,i])
  }
}

data_encoded$PID = data$PID
data_encoded$Sale_Price = data$Sale_Price
data_encoded$Sale_Price_Log = log(data$Sale_Price)

fit = lm(Sale_Price_Log ~ Lot_Area + Mas_Vnr_Area + BsmtFin_SF_2 + Bsmt_Unf_SF + Total_Bsmt_SF + Second_Flr_SF + First_Flr_SF + Gr_Liv_Area + Garage_Area + Wood_Deck_SF + Open_Porch_SF + Enclosed_Porch + Three_season_porch + Screen_Porch + Misc_Val, data = data_encoded)
fit_cd = cooks.distance(fit)
data_encoded = data_encoded[fit_cd < 4 / length(fit_cd),]


#data_encoded$Lot_Area = log(data_encoded$Lot_Area)
#data_encoded$First_Flr_SF = log(data_encoded$First_Flr_SF)


paste("Number of Missing Values", sum(is.na(data_encoded)))
data_encoded <- data_encoded %>% 
                    fill(
                      dplyr::everything()
                    )


# counting number of missing values
paste("Number of Missing Values", sum(is.na(data_encoded)))


testIDs <- read.table("project1_testIDs.dat")
j <- 2
train <- data_encoded[-testIDs[,j], ]
test <- data_encoded[testIDs[,j], ]
#test.y <- test[, c(1, 136,137)]
#test <- test[, -c(136,137)]
test.y <- test[, c("PID", "Sale_Price","Sale_Price_Log")]
test <- test[, !names(test) %in% c("Sale_Price","Sale_Price_Log")]

write.csv(train,"train.csv",row.names=FALSE)
write.csv(test, "test.csv",row.names=FALSE)
write.csv(test.y,"test_y.csv",row.names=FALSE)

trainData <- read.csv("train.csv")
testData <- read.csv("test.csv")
testData = testData[complete.cases(testData),]
test.y = test.y[complete.cases(test.y),]
```


```{r}
dim(trainData)
dim(testData)
```


```{r}
 xgb.fit1 <- xgb.cv(
   data = trainData %>% as.matrix(),
   label = trainData$Sale_Price_Log,
   nrounds = 2000,
   nfold = 5,
   objective = "reg:linear",  # for regression models
   verbose = 0               # silent,
   #early_stopping_rounds = 10
 )
 
 xgb.fit1$evaluation_log %>%
   dplyr::summarise(
     ntrees.train = which(train_rmse_mean == min(train_rmse_mean))[1],
     rmse.train   = min(train_rmse_mean),
     ntrees.test  = which(test_rmse_mean == min(test_rmse_mean))[1],
     rmse.test   = min(test_rmse_mean),
   )

```

```{r}
```

```{r}
set.seed(4)

X = trainData[,!names(trainData) %in% c("Sale_Price","Sale_Price_Log","PID")]

cv_lasso=cv.glmnet(as.matrix(X),trainData$Sale_Price_Log, nfolds = 10, alpha = 1)
cv_lasso$lambda.min

# select variables
sel.vars <- predict(cv_lasso, type="nonzero", s = cv_lasso$lambda.min)$X1
 
lasso_mod = cv.glmnet(as.matrix(X[,sel.vars]), trainData$Sale_Price_Log, alpha = 1)

# ## Predictions
preds_train<-predict(lasso_mod,newx=as.matrix(X[,sel.vars]),s=cv_lasso$lambda.min, alpha = 1)
RMSE(trainData$Sale_Price_Log,preds_train)
#trainData$pred_sale_price = preds_train

preds<-predict(lasso_mod,newx=as.matrix(testData[,sel.vars]),s=cv_lasso$lambda.min, alpha = 1)
RMSE(test.y$Sale_Price_Log,preds)
test.y$pred_sale_price = preds
 
 
 
```
```{r}
set.seed(471)
n = 10
nr = nrow(trainData)
#train.10 = split(trainData, f = rep_len(1:n,nr))
train.10 = split(trainData, sample(1:n, nr, replace =T ))
for(i in 1:length(train.10)) {
  trainData1 = train.10[[i]]
  X = trainData1[,!names(trainData1) %in% c("Sale_Price","Sale_Price_Log","PID")]
  preds_train<-predict(lasso_mod,newx=as.matrix(X[,sel.vars]),s=cv_lasso$lambda.min, alpha = 1)
  print(RMSE(trainData1$Sale_Price_Log,preds_train))
}
nr = nrow(test.y)
test1Data = merge(testData, test.y, by = "PID")
test.y.10 = split(test1Data, sample(1:n, nr, replace = TRUE ))
#test.y.10 = split(test1Data, f= rep_len(1:n,nr))
for(i in 1:length(test.y.10)) {
  testData1 = test.y.10[[i]]
  X = testData1[,!names(testData1) %in% c("Sale_Price","Sale_Price_Log","PID","pred_sale_price")]
  preds_test<-predict(lasso_mod,newx=as.matrix(X[,sel.vars]),s=cv_lasso$lambda.min, alpha = 1)
  print(RMSE(testData1$Sale_Price_Log,preds_test))
}

```


```{r}
plot(cv_lasso)
```


```{r}
pred <- read.csv("mysubmission1.txt")
names(test.y)[2] <- "True_Sale_Price"
pred <- merge(pred, test.y, by="PID")
sqrt(mean((log(pred$Sale_Price) - log(pred$True_Sale_Price))^2))

pred <- read.csv("mysubmission2.txt")
names(test.y)[2] <- "True_Sale_Price"
pred <- merge(pred, test.y, by="PID")
sqrt(mean((log(pred$Sale_Price) - log(pred$True_Sale_Price))^2))
```


```{r}
mean(c(0.1230802,
0.1205381,
0.1199168,
0.1206789,
0.1128222,
0.1320535,
0.1252759,
0.1193803,
0.1300544,
0.1247375))
```



```{r}
start.time <- Sys.time()

dtrain <- xgb.DMatrix(data = as.matrix(trainData[,!names(trainData) %in% c("Sale_Price","Sale_Price_Log")]), label = as.matrix(trainData$Sale_Price_Log)) 
dtest <- xgb.DMatrix(data = as.matrix(testData), label=test.y$Sale_Price_Log)
registerDoMC(8)
# Create empty lists
lowest_error_list = list()
parameters_list = list()

# Create 10,000 rows with random hyperparameters
set.seed(8742)
for (iter in 1:1000){
  param <- list(booster = "gbtree",
                objective = "reg:squarederror",
                max_depth = sample(4:6, 1),
                eta = runif(1, .01, .05),
                subsample = runif(1, .5, 0.6)
    )
  parameters <- as.data.frame(param)
  parameters_list[[iter]] <- parameters
}

# Create object that contains all randomly created hyperparameters
parameters_df = do.call(rbind, parameters_list)


# Use randomly created parameters to create 10,000 XGBoost-models
for (row in 1:nrow(parameters_df)){
  set.seed(8742)
  mdcv <- xgb.train(data = dtrain, nfold = 5, 
                    booster = "gbtree",
                    objective = "reg:squarederror",
                    max_depth = parameters_df$max_depth[row],
                    eta = parameters_df$eta[row],
                    subsample = parameters_df$subsample[row],
                    nrounds= 1000,
                    eval_metric = "rmse",
                    early_stopping_rounds= 30,
                    print_every_n = 100,
                    watchlist = list(train= dtrain, val= dtest)
  )
  lowest_error <- as.data.frame(1 - min(mdcv$evaluation_log$val_error))
  lowest_error_list[[row]] <- lowest_error
}

# Create object that contains all accuracy's
lowest_error_df = do.call(rbind, lowest_error_list)

# Bind columns of accuracy values and random hyperparameter values
randomsearch = cbind(lowest_error_df, parameters_df)

# Quickly display highest accuracy
max(randomsearch$`1 - min(mdcv$evaluation_log$val_error)`)

# Stop time and calculate difference
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```

```{r}
set.seed(8742)
xgbFit = xgboost(data = as.matrix(trainData[,!names(trainData) %in% c("Sale_Price","Sale_Price_Log","pred_sale_price")]), nfold = 5, label = as.matrix(trainData$Sale_Price_Log), 
    nrounds = 2200, verbose = FALSE, objective = "reg:linear", eval_metric = "rmse", 
    nthread = 8, eta = 0.01, max_depth = 6, 
    subsample = 0.5213)
## print(xgbFit)

## Predictions
# rmse of training data
predict_rf_train = predict(xgbFit, newdata = as.matrix(trainData[,!names(trainData) %in% c("Sale_Price","Sale_Price_Log","pred_sale_price")]))
RMSE(trainData$Sale_Price_Log, predict_rf_train)
# rmse of testing data
preds2 <- predict(xgbFit, newdata = as.matrix(testData))
RMSE(test.y$Sale_Price_Log, preds2)
test.y$pred_sale_price = round(exp(preds2),1)
mysubm2 = data.frame(test.y[,c("PID","pred_sale_price")])
colnames(mysubm2) = c("PID","Sale_Price")
write.csv(mysubm2, file = "mysubmission2.txt", row.names = FALSE)

```

