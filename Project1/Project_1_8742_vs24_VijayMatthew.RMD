---
title: "PSL (F20) Project 1"
author: "Vijayakumar Sitha Mohan (VS24), Waitong Matthew Leung (wmleung2)"
date: '13-Sept-2020'
output:
  html_document: 
    theme: readable
    toc: yes
  pdf_document: default
urlcolor: cyan
---


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(scipen = 1, digits = 4, width = 80, fig.align = "center")
set.seed(8742)

library(dplyr)
library(tidyr)
library(caret)
library(tidyr)
library(knitr)
library(xgboost)
library(glmnet)
library(e1071)
```

## Introduction

The goal is to predict the final price of a home (in log scale) using AMES housing dataset. As a project requirement we need to build Two prediction models and we chose Lasso/Ridge Regression and XBGBoost as our model to predict the sale price.

```{r echo=FALSE}
# Utility Functions

hotEncoding = function(dataset, testFlag) {
  if(testFlag == TRUE) {
    dummies_model =  dummyVars(" ~ .", data=dataset)
  }
  else {
    dummies_model= dummyVars(Sale_Price ~ ., data=dataset)
  }
  dataset = predict(dummies_model, newdata = dataset)
  dataset = data.frame(dataset)
  return(dataset)
}

RMSE = function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}


removeVars = function(data, remove.var) {
  
  data[,!names(data) %in% remove.var]
}


winsorize = function(data, winsor.vars) {

  quan.value <- 0.95
  for(var in winsor.vars){
    tmp <- data[, var]
    myquan <- quantile(tmp, probs = quan.value, na.rm = TRUE)
    tmp[tmp > myquan] <- myquan
    data[, var] <- tmp
  }
  data
}

getSkewedVars = function(data) {
  skewedVars <- NA

  for(i in names(data)){
    if(is.numeric(data[,i])){
      if((i != "Sale_Price") & (i != "PID")){
        if(length(levels(as.factor(data[,i]))) > 10){
          # Enters this block if variable is non-categorical
          skewVal <- skewness(data[,i])
          if(abs(skewVal) > 0.5){
            skewedVars <- c(skewedVars, i)
          }
        }
      }
    }
  }
  skewedVars[-1]
}

remove.var <- c('Street', 'Utilities',  'Condition_2', 'Roof_Matl', 'Heating', 'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude','Latitude')

winsor.vars <- c("Lot_Frontage", "Lot_Area", "Mas_Vnr_Area", "BsmtFin_SF_2", "Bsmt_Unf_SF", "Total_Bsmt_SF", "Second_Flr_SF", 'First_Flr_SF', "Gr_Liv_Area", "Garage_Area", "Wood_Deck_SF", "Open_Porch_SF", "Enclosed_Porch", "Three_season_porch", "Screen_Porch", "Misc_Val")

myPreProcess = function(data,testFlag) {

  d <- preProcess(data, "medianImpute")
  data = predict(d,data)
  data = winsorize(data, winsor.vars)
  data_encoded = hotEncoding(data,testFlag)
  data_encoded = removeVars(data_encoded,remove.var)
  data_encoded$PID = data$PID
  data_encoded$Sale_Price = data$Sale_Price
  data_encoded$Sale_Price_Log = log(data$Sale_Price)
  data_encoded <- data_encoded %>% 
    fill(
      dplyr::everything()
    )
  data_encoded
}
```


## Data Exploration

```{r echo=FALSE}
data = read.csv("Ames_data.csv")
```

The dataset has 2930 rows (i.e., houses) and 83 columns.
    The first column is “PID”, the Parcel identification number;
    The last column is the response variable, Sale_Price;
    The remaining 81 columns are explanatory variables describing (almost) every aspect of residential homes.

- Analysis of Response Variable(Sale Price)

    A mean and median sale price of $180,796 and $160,000 respectively, indicating a positive skew, which was confirmed by histogram of the Sale Price.

    A long right tail tells that there are outlier data points. max = 755,000 and min = 12,789

- Skewness also in quite a few variables

```{r echo=FALSE}
par(mfrow=c(1,4),pin=c(1,2))
hist(data$Sale_Price,col = "blue", main = "Histogram of Sale Price", xlab = "Sale Price")

plot(Sale_Price ~ Gr_Liv_Area, data = data)
plot(Sale_Price ~ Garage_Area, data = data)
plot(Sale_Price ~ Lot_Area, data = data)
```

## Overall Approach

We chose the following two models to tackle this home price prediction problem. The general approach of both of the models are in the sequence of data prepreprocessing, optimal hyperparameters search, train model based on train data set and finally predict sale price with test data set.

- Model 1: Lasso and Ridge mixed model. We use Lasso 10-fold cross validation to select relevant variables and lambda value first. Subsequently, We use selected variables and lambda value from Lasso to train Ridge model in order to remove colinearity of remaining variables.

- Model 2: XGBoost model. We spent quite a lot of time (~16 hours) to search for the optimal value for the following hyperparameters, namely eta, max_depth, subsample. We randomly generated 10,000 combination of the three hyperparameters to select the set that give us minimal RMSE.


### Data PreProcessing

- Remove some predictors with imbalance data or can be inferred from other predictors, i.e. 'Street', 'Utilities',  'Condition_2', 'Roof_Matl', 'Heating', 'Pool_QC', 'Misc_Feature', 'Low_Qual_Fin_SF', 'Pool_Area', 'Longitude','Latitude'.

- Impute Missing Values with median value using Caret package

- Winsorize numerical variables by 95 percentile value

- Encode categorical variables to numerical value

- For model 2 XGBoost model, remove outliners in train set based on cook's distance (remove train data with cook's distance > 4/n)


```{r echo= FALSE}

data = read.csv("Ames_data.csv")
testIDs <- read.table("project1_testIDs.dat")
j <- 4
train <- data[-testIDs[,j], ]
test <- data[testIDs[,j], ]

test.y <- test[, c("PID", "Sale_Price")]
test <- test[, !names(test) %in% c("Sale_Price")]

write.csv(train,"train.csv",row.names=FALSE)
write.csv(test, "test.csv",row.names=FALSE)
write.csv(test.y,"test_y.csv",row.names=FALSE)

trainData <- read.csv("train.csv")
testData <- read.csv("test.csv")

trainData = myPreProcess(trainData,FALSE)
testData1 = merge(testData, test.y, by = "PID")
testData = myPreProcess(testData1,TRUE)
trainData_XG =trainData
fit = lm(Sale_Price ~ Lot_Area + Mas_Vnr_Area , data = trainData)
fit_cd = cooks.distance(fit)
trainData = trainData[fit_cd < 4 / length(fit_cd),]

```

### Model Building

#### Model 1: LASSO/Ridge Regression Model 

- Lasso 10 Fold Cross Validation to choose Lamda hyperparameter

```{r echo=FALSE}
set.seed(8742)
X = trainData[,!names(trainData) %in% c("Sale_Price","Sale_Price_Log","PID")]
cv_lasso=cv.glmnet(as.matrix(X),trainData$Sale_Price_Log, nfolds = 10, alpha = 1)
#cv_lasso$lambda.min
```

- Lasso Feature Engineering to select variables with non zero coefficients

```{r echo=FALSE}
# select variables
sel.vars <- predict(cv_lasso, type="nonzero", s = cv_lasso$lambda.min)$X1
sel.vars = names(X[,sel.vars])
```

- Ridge Fit & Predict using optimal hyperparameters

```{r echo=FALSE}
lasso_mod = cv.glmnet(as.matrix(X[,sel.vars]), trainData$Sale_Price_Log, alpha = 1)
train_lasso_vars = sel.vars
# ## Predictions
preds_train<-predict(lasso_mod,newx=as.matrix(X[,sel.vars]),s=cv_lasso$lambda.min, alpha = 0)
tr.err=RMSE(trainData$Sale_Price_Log,preds_train)
#trainData$pred_sale_price = preds_train

missing = setdiff(sel.vars,names(testData))
testData[missing] = 0
preds<-predict(lasso_mod,newx=as.matrix(testData[,sel.vars]),s=cv_lasso$lambda.min, alpha = 0)
tst.err=RMSE(testData$Sale_Price_Log,preds)
testData$pred_sale_price = preds
#knitr::kable(data.frame(train_rmse=tr.err, test_rmse=tst.err))
```

#### Model 2: XGBoost - Boosting Model

- Train model to choose eta, subsample, max_depth hyperparameter: Ran model selection by running 10000 times and chose the lowest test rmse and corresponding hyperparameter values. Run time was around ~16 hours

- Optimal hyperparameters: (eta = 0.0474239, max_depth = 4, subsample = 0.541795)

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
set.seed(8742)
start.time <- Sys.time()
X = trainData_XG[,!names(trainData_XG) %in% c("Sale_Price","Sale_Price_Log")]
dtrain <- xgb.DMatrix(data = as.matrix(X), label = as.matrix(trainData_XG$Sale_Price_Log)) 
missing = setdiff(names(trainData_XG),names(testData))
testData[missing] = 0
dtest <- xgb.DMatrix(data = as.matrix(testData[,names(X)]), label=testData$Sale_Price_Log)
# Create empty lists
lowest_error_list = list()
parameters_list = list()
# Create 10,000 rows with random hyperparameters
set.seed(8742)
#for (iter in 1:10000){  # use this line only during hyperparameter search (runs 16hrs)
for (iter in 1:1){       # use this line otherwise
  param <- list(booster = "gbtree",
                objective = "reg:squarederror",
                max_depth = sample(4:6, 1),
                eta = runif(1, .04, .05),
                subsample = runif(1, .5, 0.6)
    )
  parameters <- as.data.frame(param)
  parameters_list[[iter]] <- parameters
}
# Create object that contains all randomly created hyperparameters
parameters_df = do.call(rbind, parameters_list)

# Use randomly created parameters to create 10,000 XGBoost-models
for (row in 1:nrow(parameters_df)){
  set.seed(8742)
  mdcv <- xgb.train(data = dtrain, booster = "gbtree",objective = "reg:squarederror",
                    max_depth = parameters_df$max_depth[row], eta = parameters_df$eta[row],
                    subsample = parameters_df$subsample[row], nrounds= 1000,  eval_metric = "rmse",
                    early_stopping_rounds= 30,verbose = FALSE,watchlist = list(train= dtrain, val= dtest)
  )
  lowest_error = mdcv$evaluation_log[mdcv$best_iteration,]
  lowest_error_list[[row]] = lowest_error
}

# Create object that contains all accuracy's
lowest_error_df = do.call(rbind, lowest_error_list)

# Bind columns of accuracy values and random hyperparameter values
randomsearch = cbind(lowest_error_df, parameters_df)

# Quickly display highest accuracy
best_xg_param = randomsearch[which(randomsearch$val_rmse == min(randomsearch$val_rmse)),]

# Stop time and calculate difference
end.time = Sys.time()
time.taken = end.time - start.time
```

+ Fit & Predict using optimal hyperparameters

```{r echo=FALSE, message=FALSE, warning=FALSE}
set.seed(8742)
X = trainData_XG[,!names(trainData_XG) %in% c("Sale_Price","Sale_Price_Log","PID")]
train_xg_vars = names(X)
xgbFit = xgboost(data = as.matrix(X), label = as.matrix(trainData_XG$Sale_Price_Log), 
                 nrounds = 1000, verbose = FALSE, objective = "reg:squarederror", eval_metric = "rmse", 
                 eta = 0.0474239, max_depth = 4, subsample = 0.541795)
## Predictions
# rmse of training data
predict_rf_train = predict(xgbFit, newdata = as.matrix(X))
tr.err = RMSE(trainData_XG$Sale_Price_Log, predict_rf_train)
# rmse of testing data
missing = setdiff(names(trainData),names(testData))
testData[missing] = 0
preds2 <- predict(xgbFit, newdata = as.matrix(testData[,names(X)]))
tst.err = RMSE(testData$Sale_Price_Log, preds2)

#mysubm2 = data.frame(PID=testData[,c("PID")],Sale_Price=round(exp(preds2),1))
#colnames(mysubm2) = c("PID","Sale_Price")
#write.csv(mysubm2, file = "mysubmission2.txt", row.names = FALSE, quote = FALSE)

#knitr::kable(data.frame(train_rmse=tr.err, test_rmse=tst.err))
```

## Results

- The below two tables shows the individual split train and test errors for both models and other table shows the mean errors of the same.

```{r echo=FALSE}
set.seed(8742)
n = 10
nr = nrow(trainData)
lasso.train.error = rep(0,n)
lasso.test.error = rep(0,n)
lasso.time = rep(0,n)

for(j in 1:n) {
  
  start.time = Sys.time()

  train <- data[-testIDs[,j], ]
  test <- data[testIDs[,j], ]
  
  test.y <- test[, c("PID", "Sale_Price")]
  test <- test[, !names(test) %in% c("Sale_Price")]
  
  trainData = myPreProcess(train,FALSE)
  testData1 = merge(test, test.y, by = "PID")
  testData = myPreProcess(testData1,TRUE)
  fit = lm(Sale_Price ~ Lot_Area + Mas_Vnr_Area , data = trainData)
  fit_cd = cooks.distance(fit)
  trainData = trainData[fit_cd < 4 / length(fit_cd),]
  
  missing = setdiff(train_lasso_vars,names(trainData))
  trainData[missing] = 0
    
  X = trainData[,train_lasso_vars]
  preds_train<-predict(lasso_mod,newx=as.matrix(X),s=cv_lasso$lambda.min, alpha = 0)
  lasso.train.error[j] = (RMSE(trainData$Sale_Price_Log,preds_train))

  missing = setdiff(train_lasso_vars,names(testData))
  testData[missing] = 0
  preds_test<-predict(lasso_mod,newx=as.matrix(testData[,train_lasso_vars]),s=cv_lasso$lambda.min, alpha = 0)
  lasso.test.error[j] = (RMSE(testData$Sale_Price_Log,preds_test))
  
  # Stop time and calculate difference
  end.time = Sys.time()
  lasso.time[j] = end.time - start.time
}

```


```{r echo=FALSE}
set.seed(8742)
n = 10
nr = nrow(trainData)
xg.train.error = rep(0,n)
xg.test.error = rep(0,n)
xg.time = rep(0,n)

for(j in 1:n) {
  
  start.time = Sys.time()
    
  train <- data[-testIDs[,j], ]
  test <- data[testIDs[,j], ]
  
  test.y <- test[, c("PID", "Sale_Price")]
  test <- test[, !names(test) %in% c("Sale_Price")]
  
  trainData = myPreProcess(train,FALSE)
  testData1 = merge(test, test.y, by = "PID")
  testData = myPreProcess(testData1,TRUE)
  
  missing = setdiff(train_xg_vars,names(trainData))
  trainData[missing] = 0
    
  X = trainData[,train_xg_vars]
  preds_train = predict(xgbFit, newdata = as.matrix(X))
  xg.train.error[j] = (RMSE(trainData$Sale_Price_Log,preds_train))
  
  # rmse of testing data
  missing = setdiff(names(X),names(testData))
  testData[missing] = 0
  
  X = testData[,names(X)]
  preds_test = predict(xgbFit, newdata = as.matrix(X))
  xg.test.error[j] = (RMSE(testData$Sale_Price_Log,preds_test))

  # Stop time and calculate difference
  end.time = Sys.time()
  xg.time[j] = end.time - start.time  
}
```

- 10 Train & Test Split Error for Lasso & XGBoost Model

```{r echo=FALSE}
results = data.frame(cbind(seq(1,10),lasso.test.error,xg.test.error))
colnames(results)=c("Split #", "Lasso Test Error", "XGBoost Test Error")
knitr::kable(results)


```

- Mean Train & Test Error for Lasso & XGBoost Model

```{r echo=FALSE}
results %>%
   dplyr::summarise(lasso.train.error = mean(lasso.train.error),
                    lasso.test.error = mean(lasso.test.error),
                    xgboost.train.error = mean(xg.train.error),
                    xgboost.test.error = mean(xg.test.error))
```

- Running time

System: MSI laptop, Intel i7, 2.60GHz, 16GB, Win 10

```{r echo=FALSE}

run.time = data.frame(cbind(sum(lasso.time), sum(xg.time)))
colnames(run.time) = c("Lasso total train & test time (second)", "XGBoost total train & test time (second)")
knitr::kable(run.time)
```



## Discussion

These are important observations we had during model building.

  1. We were not able to satisfy bench mark RMSE requirement for regression model by using only Lasso or Ridge regularization alone. We ended up need to have extra train data preprocessing to remove outliners based on cook's distance. We also need to use Lasso to drop insignificant variables, and cross-validation to get lambda min first. We then use Ridge to regularize the remaining variables which have colinearity among them.
  
  2. The hyperparameter tuning for XGBoost runs too long and to tune Lambda, MaX_Depth and SubSample, took 16 hours to find the optimal value by running 10000 models in my laptop. Need to work on parallelizing the code with doMC package or SParkR to improve the performance.

  3. There are quite a few variables with skewness. We tried to put in transformation to skewed variables but no improvement in prediction accuracy.